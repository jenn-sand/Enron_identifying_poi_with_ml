{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from tester import test_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(\n",
    "    open(\"../final_project/final_project_dataset.pkl\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select what features to use:\n",
    "\n",
    "#all in USD, features ordered like financial pdf:\n",
    "financial_features = [\n",
    "    'salary', 'bonus', 'long_term_incentive', 'deferred_income',\n",
    "    'deferral_payments', 'loan_advances', 'other', 'expenses', 'director_fees',\n",
    "    'total_payments', 'exercised_stock_options', 'restricted_stock',\n",
    "    'restricted_stock_deferred', 'total_stock_value'\n",
    "]\n",
    "#(units are generally number of emails messages; notable exception is ‘email_address’, which is a text string)\n",
    "email_features = [\n",
    "    'to_messages', 'email_address', 'from_poi_to_this_person', 'from_messages',\n",
    "    'from_this_person_to_poi', 'shared_receipt_with_poi'\n",
    "]\n",
    "\n",
    "#for now, use all.  Let's trim later.\n",
    "features_list = financial_features + email_features + ['poi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bonus', 'deferral_payments', 'deferred_income', 'director_fees',\n",
       "       'email_address', 'exercised_stock_options', 'expenses',\n",
       "       'from_messages', 'from_poi_to_this_person',\n",
       "       'from_this_person_to_poi', 'loan_advances', 'long_term_incentive',\n",
       "       'other', 'poi', 'restricted_stock', 'restricted_stock_deferred',\n",
       "       'salary', 'shared_receipt_with_poi', 'to_messages',\n",
       "       'total_payments', 'total_stock_value'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Move data into pandas dataframe\n",
    "#Cribbed heavily from Miles: https://discussions.udacity.com/t/pickling-pandas-df/174753\n",
    "df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "df.columns.values\n",
    "# __, cols = df.shape\n",
    "# print cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>3.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.020000e+02</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>6.600000e+01</td>\n",
       "      <td>9.300000e+01</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>9.500000e+01</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.250000e+02</td>\n",
       "      <td>1.260000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.374235e+06</td>\n",
       "      <td>1.642674e+06</td>\n",
       "      <td>-1.140475e+06</td>\n",
       "      <td>1.668049e+05</td>\n",
       "      <td>5.987054e+06</td>\n",
       "      <td>1.087289e+05</td>\n",
       "      <td>608.790698</td>\n",
       "      <td>64.895349</td>\n",
       "      <td>41.232558</td>\n",
       "      <td>4.196250e+07</td>\n",
       "      <td>1.470361e+06</td>\n",
       "      <td>9.190650e+05</td>\n",
       "      <td>2.321741e+06</td>\n",
       "      <td>1.664106e+05</td>\n",
       "      <td>5.621943e+05</td>\n",
       "      <td>1176.465116</td>\n",
       "      <td>2073.860465</td>\n",
       "      <td>5.081526e+06</td>\n",
       "      <td>6.773957e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.071333e+07</td>\n",
       "      <td>5.161930e+06</td>\n",
       "      <td>4.025406e+06</td>\n",
       "      <td>3.198914e+05</td>\n",
       "      <td>3.106201e+07</td>\n",
       "      <td>5.335348e+05</td>\n",
       "      <td>1841.033949</td>\n",
       "      <td>86.979244</td>\n",
       "      <td>100.073111</td>\n",
       "      <td>4.708321e+07</td>\n",
       "      <td>5.942759e+06</td>\n",
       "      <td>4.589253e+06</td>\n",
       "      <td>1.251828e+07</td>\n",
       "      <td>4.201494e+06</td>\n",
       "      <td>2.716369e+06</td>\n",
       "      <td>1178.317641</td>\n",
       "      <td>2582.700981</td>\n",
       "      <td>2.906172e+07</td>\n",
       "      <td>3.895777e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>-1.025000e+05</td>\n",
       "      <td>-2.799289e+07</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>3.285000e+03</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>6.922300e+04</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-2.604490e+06</td>\n",
       "      <td>-7.576788e+06</td>\n",
       "      <td>4.770000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>-4.409300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.312500e+05</td>\n",
       "      <td>8.157300e+04</td>\n",
       "      <td>-6.948620e+05</td>\n",
       "      <td>9.878400e+04</td>\n",
       "      <td>5.278862e+05</td>\n",
       "      <td>2.261400e+04</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>2.812500e+05</td>\n",
       "      <td>1.215000e+03</td>\n",
       "      <td>2.540180e+05</td>\n",
       "      <td>-3.896218e+05</td>\n",
       "      <td>2.118160e+05</td>\n",
       "      <td>249.750000</td>\n",
       "      <td>541.250000</td>\n",
       "      <td>3.944750e+05</td>\n",
       "      <td>4.945102e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.693750e+05</td>\n",
       "      <td>2.274490e+05</td>\n",
       "      <td>-1.597920e+05</td>\n",
       "      <td>1.085790e+05</td>\n",
       "      <td>1.310814e+06</td>\n",
       "      <td>4.695000e+04</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.176250e+07</td>\n",
       "      <td>4.420350e+05</td>\n",
       "      <td>5.238200e+04</td>\n",
       "      <td>4.517400e+05</td>\n",
       "      <td>-1.469750e+05</td>\n",
       "      <td>2.599960e+05</td>\n",
       "      <td>740.500000</td>\n",
       "      <td>1211.000000</td>\n",
       "      <td>1.101393e+06</td>\n",
       "      <td>1.102872e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.002672e+06</td>\n",
       "      <td>-3.834600e+04</td>\n",
       "      <td>1.137840e+05</td>\n",
       "      <td>2.547724e+06</td>\n",
       "      <td>7.995250e+04</td>\n",
       "      <td>145.500000</td>\n",
       "      <td>72.250000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>8.212500e+07</td>\n",
       "      <td>9.386720e+05</td>\n",
       "      <td>3.620960e+05</td>\n",
       "      <td>1.002370e+06</td>\n",
       "      <td>-7.500975e+04</td>\n",
       "      <td>3.121170e+05</td>\n",
       "      <td>1888.250000</td>\n",
       "      <td>2634.750000</td>\n",
       "      <td>2.093263e+06</td>\n",
       "      <td>2.949847e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.734362e+07</td>\n",
       "      <td>3.208340e+07</td>\n",
       "      <td>-8.330000e+02</td>\n",
       "      <td>1.398517e+06</td>\n",
       "      <td>3.117640e+08</td>\n",
       "      <td>5.235198e+06</td>\n",
       "      <td>14368.000000</td>\n",
       "      <td>528.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>8.392500e+07</td>\n",
       "      <td>4.852193e+07</td>\n",
       "      <td>4.266759e+07</td>\n",
       "      <td>1.303223e+08</td>\n",
       "      <td>1.545629e+07</td>\n",
       "      <td>2.670423e+07</td>\n",
       "      <td>5521.000000</td>\n",
       "      <td>15149.000000</td>\n",
       "      <td>3.098866e+08</td>\n",
       "      <td>4.345095e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "count  8.200000e+01       3.900000e+01     4.900000e+01   1.700000e+01   \n",
       "mean   2.374235e+06       1.642674e+06    -1.140475e+06   1.668049e+05   \n",
       "std    1.071333e+07       5.161930e+06     4.025406e+06   3.198914e+05   \n",
       "min    7.000000e+04      -1.025000e+05    -2.799289e+07   3.285000e+03   \n",
       "25%    4.312500e+05       8.157300e+04    -6.948620e+05   9.878400e+04   \n",
       "50%    7.693750e+05       2.274490e+05    -1.597920e+05   1.085790e+05   \n",
       "75%    1.200000e+06       1.002672e+06    -3.834600e+04   1.137840e+05   \n",
       "max    9.734362e+07       3.208340e+07    -8.330000e+02   1.398517e+06   \n",
       "\n",
       "       exercised_stock_options      expenses  from_messages  \\\n",
       "count             1.020000e+02  9.500000e+01      86.000000   \n",
       "mean              5.987054e+06  1.087289e+05     608.790698   \n",
       "std               3.106201e+07  5.335348e+05    1841.033949   \n",
       "min               3.285000e+03  1.480000e+02      12.000000   \n",
       "25%               5.278862e+05  2.261400e+04      22.750000   \n",
       "50%               1.310814e+06  4.695000e+04      41.000000   \n",
       "75%               2.547724e+06  7.995250e+04     145.500000   \n",
       "max               3.117640e+08  5.235198e+06   14368.000000   \n",
       "\n",
       "       from_poi_to_this_person  from_this_person_to_poi  loan_advances  \\\n",
       "count                86.000000                86.000000   4.000000e+00   \n",
       "mean                 64.895349                41.232558   4.196250e+07   \n",
       "std                  86.979244               100.073111   4.708321e+07   \n",
       "min                   0.000000                 0.000000   4.000000e+05   \n",
       "25%                  10.000000                 1.000000   1.600000e+06   \n",
       "50%                  35.000000                 8.000000   4.176250e+07   \n",
       "75%                  72.250000                24.750000   8.212500e+07   \n",
       "max                 528.000000               609.000000   8.392500e+07   \n",
       "\n",
       "       long_term_incentive         other  restricted_stock  \\\n",
       "count         6.600000e+01  9.300000e+01      1.100000e+02   \n",
       "mean          1.470361e+06  9.190650e+05      2.321741e+06   \n",
       "std           5.942759e+06  4.589253e+06      1.251828e+07   \n",
       "min           6.922300e+04  2.000000e+00     -2.604490e+06   \n",
       "25%           2.812500e+05  1.215000e+03      2.540180e+05   \n",
       "50%           4.420350e+05  5.238200e+04      4.517400e+05   \n",
       "75%           9.386720e+05  3.620960e+05      1.002370e+06   \n",
       "max           4.852193e+07  4.266759e+07      1.303223e+08   \n",
       "\n",
       "       restricted_stock_deferred        salary  shared_receipt_with_poi  \\\n",
       "count               1.800000e+01  9.500000e+01                86.000000   \n",
       "mean                1.664106e+05  5.621943e+05              1176.465116   \n",
       "std                 4.201494e+06  2.716369e+06              1178.317641   \n",
       "min                -7.576788e+06  4.770000e+02                 2.000000   \n",
       "25%                -3.896218e+05  2.118160e+05               249.750000   \n",
       "50%                -1.469750e+05  2.599960e+05               740.500000   \n",
       "75%                -7.500975e+04  3.121170e+05              1888.250000   \n",
       "max                 1.545629e+07  2.670423e+07              5521.000000   \n",
       "\n",
       "        to_messages  total_payments  total_stock_value  \n",
       "count     86.000000    1.250000e+02       1.260000e+02  \n",
       "mean    2073.860465    5.081526e+06       6.773957e+06  \n",
       "std     2582.700981    2.906172e+07       3.895777e+07  \n",
       "min       57.000000    1.480000e+02      -4.409300e+04  \n",
       "25%      541.250000    3.944750e+05       4.945102e+05  \n",
       "50%     1211.000000    1.101393e+06       1.102872e+06  \n",
       "75%     2634.750000    2.093263e+06       2.949847e+06  \n",
       "max    15149.000000    3.098866e+08       4.345095e+08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The data set is using the string 'NaN' instead of nan, which doesn't play well with describe\n",
    "df = df.replace('NaN', np.nan)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persons of interest: 18\n",
      "There are 146 persons in the data, 35 or 23.97% are persons of interest.\n"
     ]
    }
   ],
   "source": [
    "persons_of_interest = [k for k in data_dict if data_dict[k]['poi']]\n",
    "\n",
    "#known issue in this data -- email list is restricted to persons of interest who worked for Enron\n",
    "print 'persons of interest: {0}'.format(len(persons_of_interest))\n",
    "poi_names = pd.read_csv(\"../final_project/poi_names.txt\", \"\\s+\")\n",
    "\n",
    "print(\n",
    "    'There are {0} persons in the data, {1} or {2:.2f}% are persons of interest.'\n",
    ").format(len(df), len(poi_names), 100. * len(poi_names) / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where is data missing?  What values have NaN, and what percentage of those is missing data?\n",
      "bonus NaN values: 64 people = 43.84%\n",
      "deferral_payments NaN values: 107 people = 73.29%\n",
      "deferred_income NaN values: 97 people = 66.44%\n",
      "director_fees NaN values: 129 people = 88.36%\n",
      "email_address NaN values: 35 people = 23.97%\n",
      "exercised_stock_options NaN values: 44 people = 30.14%\n",
      "expenses NaN values: 51 people = 34.93%\n",
      "from_messages NaN values: 60 people = 41.10%\n",
      "from_poi_to_this_person NaN values: 60 people = 41.10%\n",
      "from_this_person_to_poi NaN values: 60 people = 41.10%\n",
      "loan_advances NaN values: 142 people = 97.26%\n",
      "long_term_incentive NaN values: 80 people = 54.79%\n",
      "other NaN values: 53 people = 36.30%\n",
      "poi NaN values: 0 people = 0.00%\n",
      "restricted_stock NaN values: 36 people = 24.66%\n",
      "restricted_stock_deferred NaN values: 128 people = 87.67%\n",
      "salary NaN values: 51 people = 34.93%\n",
      "shared_receipt_with_poi NaN values: 60 people = 41.10%\n",
      "to_messages NaN values: 60 people = 41.10%\n",
      "total_payments NaN values: 21 people = 14.38%\n",
      "total_stock_value NaN values: 20 people = 13.70%\n"
     ]
    }
   ],
   "source": [
    "print 'Where is data missing?  What values have NaN, and what percentage of those is missing data?'\n",
    "for col in df.columns.values:\n",
    "    isnan = df[col].isnull().sum()\n",
    "    print '{0} NaN values: {1} people = {2:.2f}%'.format(col, isnan, 100. *\n",
    "                                                         isnan / len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercised_stock_options total is: 610679485.0\n",
      "restricted_stock total is: 255391525.0\n",
      "restricted_stock_deferred total is: 2995390.0\n",
      "total_stock_value total is: 853518639.0\n",
      "\n",
      "total_stock_value should be the sum of the other stock options, as it's labeled total. Let's see if that holds true.\n",
      "\n",
      "The balanced stock data is: -15547761.0, we would expect zero.\n"
     ]
    }
   ],
   "source": [
    "#Let's see how compensation 'balances' horizontally, so we know which stock options have the richest information.\n",
    "for col in df.columns.values:\n",
    "    if 'stock' in col:\n",
    "        print '{0} total is: {1}'.format(col, df[col].sum())\n",
    "print ''\n",
    "print 'total_stock_value should be the sum of the other stock options, as it\\'s labeled total. Let\\'s see if that holds true.'\n",
    "print ''\n",
    "print 'The balanced stock data is: {0}, we would expect zero.'.format(\n",
    "    (df['total_stock_value'].sum() - df['exercised_stock_options'].sum() -\n",
    "     (df['restricted_stock'].sum() + df['restricted_stock_deferred'].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>-44093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>sanjay.bhatnagar@enron.com</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>463.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bonus  deferral_payments  deferred_income  director_fees  \\\n",
       "24     NaN          -102500.0              NaN         3285.0   \n",
       "118    NaN                NaN              NaN       137864.0   \n",
       "\n",
       "                  email_address  exercised_stock_options  expenses  \\\n",
       "24                          NaN                   3285.0       NaN   \n",
       "118  sanjay.bhatnagar@enron.com                2604490.0       NaN   \n",
       "\n",
       "     from_messages  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "24             NaN                      NaN                      NaN   \n",
       "118           29.0                      0.0                      1.0   \n",
       "\n",
       "           ...          long_term_incentive     other    poi restricted_stock  \\\n",
       "24         ...                          NaN       NaN  False              NaN   \n",
       "118        ...                          NaN  137864.0  False       -2604490.0   \n",
       "\n",
       "     restricted_stock_deferred  salary  shared_receipt_with_poi  to_messages  \\\n",
       "24                     44093.0     NaN                      NaN          NaN   \n",
       "118                 15456290.0     NaN                    463.0        523.0   \n",
       "\n",
       "     total_payments  total_stock_value  \n",
       "24         102500.0           -44093.0  \n",
       "118      15456290.0                NaN  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Who in the data has a line that isn't balancing?\n",
    "df.loc[df['total_stock_value'].fillna(0) -\n",
    "       df['exercised_stock_options'].fillna(0) -\n",
    "       (df['restricted_stock'].fillna(0) +\n",
    "        df['restricted_stock_deferred'].fillna(0)) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELFER ROBERT\n",
      "BHATNAGAR SANJAY\n"
     ]
    }
   ],
   "source": [
    "#And their names?\n",
    "print employees[24]\n",
    "print employees[118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-manually adjusting financials for BELFER ROBERT\n"
     ]
    }
   ],
   "source": [
    "#After a visual check, these two people are NOT reflecting what's in the FindLaw PDF of payments to insiders.\n",
    "print 'Semi-manually adjusting financials for {0}'.format(employees[24])\n",
    "#24 is BELFER ROBERT, his payments are all shifted to the right one starting at deferred_income.\n",
    "for col in financial_features[3:-1]:\n",
    "    col_loc = df.columns.get_loc(col)\n",
    "    next_col_loc = df.columns.get_loc(financial_features[\n",
    "        financial_features.index(col) + 1])\n",
    "    #     print col_loc, df.iloc[24,col_loc], df.iloc[24,next_col_loc]\n",
    "    df.iloc[24, col_loc] = df.iloc[24, next_col_loc]\n",
    "\n",
    "df.iloc[24, df.columns.get_loc('total_stock_value')] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-manually adjusting financials for BHATNAGAR SANJAY\n"
     ]
    }
   ],
   "source": [
    "print 'Semi-manually adjusting financials for {0}'.format(employees[118])\n",
    "\n",
    "#Sanjay's values all need to slide one to the right after 'Other', which was missing a - in the pdf.\n",
    "#Loan Advances is already NaN, so we can use that value to fill other.\n",
    "for col in reversed(financial_features[6:]):\n",
    "    col_loc = df.columns.get_loc(col)\n",
    "    prev_col_loc = df.columns.get_loc(financial_features[\n",
    "        financial_features.index(col) - 1])\n",
    "    #     print df.columns[col_loc], df.iloc[118,col_loc], df.iloc[118,prev_col_loc]\n",
    "    df.iloc[118, col_loc] = df.iloc[118, prev_col_loc]\n",
    "\n",
    "# print df.iloc[118]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exercised_stock_options total is: 623528000.0\n",
      "restricted_stock total is: 260644598.0\n",
      "restricted_stock_deferred total is: -15153576.0\n",
      "total_stock_value total is: 869019022.0\n",
      "\n",
      "total_stock_value should be the sum of the other stock options, as it's labeled total. Let's see if that holds true.\n",
      "\n",
      "The balanced stock data is now: 0.0, we would expect zero.\n"
     ]
    }
   ],
   "source": [
    "#Check the stock balancing now that we've adjusted some figures:\n",
    "for col in df.columns.values:\n",
    "    if 'stock' in col:\n",
    "        print '{0} total is: {1}'.format(col, df[col].sum())\n",
    "print ''\n",
    "print 'total_stock_value should be the sum of the other stock options, as it\\'s labeled total. Let\\'s see if that holds true.'\n",
    "print ''\n",
    "print 'The balanced stock data is now: {0}, we would expect zero.'.format(\n",
    "    (df['total_stock_value'].sum() - df['exercised_stock_options'].sum() -\n",
    "     (df['restricted_stock'].sum() + df['restricted_stock_deferred'].sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced payments data is: 0.0, we would expect zero.\n"
     ]
    }
   ],
   "source": [
    "#Let's do the same check for total payments:\n",
    "print 'The balanced payments data is: {0}, we would expect zero.'.format(\n",
    "    (df['total_payments'].sum() - df['salary'].sum() - df['bonus'].sum() -\n",
    "     df['long_term_incentive'].sum() - df['deferred_income'].sum() -\n",
    "     df['deferral_payments'].sum() - df['loan_advances'].sum() -\n",
    "     df['other'].sum() - df['expenses'].sum() - df['director_fees'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/163.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick visual check for outliers\n",
    "df[['salary', 'bonus']].iplot(\n",
    "    kind='scatter',\n",
    "    mode='markers',\n",
    "    x='salary',\n",
    "    y='bonus',\n",
    "    filename='cufflinks/simple-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TOTAL': {'bonus': 97343619,\n",
       "  'deferral_payments': 32083396,\n",
       "  'deferred_income': -27992891,\n",
       "  'director_fees': 1398517,\n",
       "  'email_address': 'NaN',\n",
       "  'exercised_stock_options': 311764000,\n",
       "  'expenses': 5235198,\n",
       "  'from_messages': 'NaN',\n",
       "  'from_poi_to_this_person': 'NaN',\n",
       "  'from_this_person_to_poi': 'NaN',\n",
       "  'loan_advances': 83925000,\n",
       "  'long_term_incentive': 48521928,\n",
       "  'other': 42667589,\n",
       "  'poi': False,\n",
       "  'restricted_stock': 130322299,\n",
       "  'restricted_stock_deferred': -7576788,\n",
       "  'salary': 26704229,\n",
       "  'shared_receipt_with_poi': 'NaN',\n",
       "  'to_messages': 'NaN',\n",
       "  'total_payments': 309886585,\n",
       "  'total_stock_value': 434509511}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_salary_bonus = {\n",
    "    k: v\n",
    "    for k, v in data_dict.items()\n",
    "    if v['bonus'] >= 90000000 and v['bonus'] <> 'NaN' and v['salary'] >=\n",
    "    26000000\n",
    "}\n",
    "\n",
    "outlier_salary_bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the total line out of _everything_.\n",
    "data_dict.pop('TOTAL', 0)\n",
    "\n",
    "total_idx = employees[employees == 'TOTAL'].index[0]\n",
    "df = df.drop(df.index[total_idx])\n",
    "\n",
    "employees = employees.drop(employees[employees == 'TOTAL'].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/163.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Re-run the visual check for outliers\n",
    "df[['salary', 'bonus']].iplot(\n",
    "    kind='scatter',\n",
    "    mode='markers',\n",
    "    x='salary',\n",
    "    y='bonus',\n",
    "    filename='cufflinks/simple-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#possible TO-DO -- imputation -- backfill all financial columns with zeroes when they're NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add a new column, total_compensation, to summarize the overall compensation someone's getting from the company.\n",
    "#this is not scaled! Stock is a smaller proportion of compensation and I do not believe it should be weighed as 'more' of the package.\n",
    "df['total_compensation'] = df['total_payments'].fillna(0) + df[\n",
    "    'total_stock_value'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the employee names into the pandas dataframe\n",
    "df = pd.concat([employees, df], axis=1)\n",
    "df = df.rename(index=str, columns={0: \"employee_name\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow the money -- were people who were significantly higher funded more likely to be persons of interest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/165.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fun with Graphs: total_payments+total_stock_value with Employee Names included\n",
    "# df[['total_payments','total_stock_value', 'employee_name', 'poi']].iplot(kind='scatter', mode='markers', x='total_payments', y='total_stock_value',\n",
    "#                                                                   text= 'poi', filename='cufflinks/simple-scatter')\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=df.total_payments,\n",
    "    y=df.total_stock_value,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size='16',\n",
    "        color=map(lambda x: 1 if x else 0, df.poi),\n",
    "        colorscale='Viridis',\n",
    "        showscale=True),\n",
    "    text=df.employee_name, )\n",
    "# layout = Layout(\n",
    "#     xaxis = dict(title='total payments'),\n",
    "#     yaxis = dict(title='total stock value'))\n",
    "py.iplot([trace], filename='scatter-plot-with-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/165.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What if it's just salary and bonus?\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x=df.salary,\n",
    "    y=df.bonus,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size='12',\n",
    "        color=map(lambda x: 1 if x else 0, df.poi),\n",
    "        colorscale='Viridis',\n",
    "        showscale=True),\n",
    "    text=df.employee_name, )\n",
    "py.iplot([trace], filename='scatter-plot-with-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simple/beautiful outlier detection function from https://github.com/joferkington/oost_paper_code/blob/master/utilities.py\n",
    "#input is a list and an optional z-score, output is a True/False for whether that specific value would be above the z-score.\n",
    "def is_outlier(points, thresh=3.5):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        thresh : The modified z-score to use as a threshold. Observations with\n",
    "            a modified z-score (based on the median absolute deviation) greater\n",
    "            than this value will be classified as outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "\n",
    "    References:\n",
    "    ----------\n",
    "        Boris Iglewicz and David Hoaglin (1993), \"Volume 16: How to Detect and\n",
    "        Handle Outliers\", The ASQC Basic References in Quality Control:\n",
    "        Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. \n",
    "    \"\"\"\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:, None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's mark the people who are extremely well paid\n",
    "df['total_comp_outlier'] = is_outlier(df.total_compensation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/165.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visual check of the z-score method\n",
    "trace = go.Scatter(\n",
    "    x=df.total_payments,\n",
    "    y=df.total_stock_value,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size='12',\n",
    "        color=map(lambda x: 1 if x else 0, is_outlier(df.total_compensation)),\n",
    "        colorscale='Viridis',\n",
    "        showscale=True),\n",
    "    text=df.employee_name, )\n",
    "py.iplot([trace], filename='scatter-plot-with-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <th>total_comp_outlier</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         employee_name\n",
       "                                 count\n",
       "poi   total_comp_outlier              \n",
       "False False                        121\n",
       "      True                           6\n",
       "True  False                         13\n",
       "      True                           5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick check of how many persons of interest were and weren't in our exceptionally well-paid category\n",
    "# df.groupby(['poi', 'total_comp_outlier']).size()\n",
    "df[['poi', 'total_comp_outlier', 'employee_name']].groupby(\n",
    "    ['poi', 'total_comp_outlier']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Because the data was gathered as part of a lawsuit, we can safely assume that any NaN values in the financial fields had no related payments.\n",
    "for col in financial_features:\n",
    "    df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the dataframe back into a dictionary\n",
    "my_dataset = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.002 s\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "prediction time: 0.001 s\n",
      "0.916666666667\n",
      "accuracy time: 0.001 s\n",
      "0.0\n",
      "recall time: 0.001 s\n",
      "There are 33 True Negatives, 0 False Positives, 3 False Negatives, and 0 True Positives\n"
     ]
    }
   ],
   "source": [
    "# #First, we'll do a basic check to see how much overall compensation could predict whether someone's a poi\n",
    "# #based on the outlier correlation we saw above, I'm assuming it's low\n",
    "features_list = ['poi', 'total_payments', 'total_stock_value']\n",
    "\n",
    "\n",
    "def create_test_split(features_list):\n",
    "    data = featureFormat(my_dataset, features_list)\n",
    "    global labels, features\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    global features_train, features_test, labels_train, labels_test\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "        train_test_split(features, labels, random_state=42, test_size=0.25)\n",
    "\n",
    "\n",
    "create_test_split(features_list)\n",
    "\n",
    "\n",
    "def classify_SVC(f_train, l_train, f_test, l_test):\n",
    "    clf = svm.SVC(kernel='rbf', C=10000)\n",
    "    t0 = time()\n",
    "\n",
    "    # features_train = features_train[:len(features_train)/100] \n",
    "    # labels_train = labels_train[:len(labels_train)/100] \n",
    "\n",
    "    clf.fit(f_train, l_train)\n",
    "    print \"training time:\", round(time() - t0, 3), \"s\"\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(f_test)\n",
    "    print pred\n",
    "    print \"prediction time:\", round(time() - t0, 3), \"s\"\n",
    "\n",
    "    t0 = time()\n",
    "    print accuracy_score(l_test, pred)\n",
    "    print \"accuracy time:\", round(time() - t0, 3), \"s\"\n",
    "\n",
    "    t0 = time()\n",
    "    print recall_score(l_test, pred)\n",
    "    print \"recall time:\", round(time() - t0, 3), \"s\"    \n",
    "    \n",
    "    cm = confusion_matrix(labels_test, pred)\n",
    "    print(\n",
    "        'There are {0} True Negatives, {1} False Positives, {2} False Negatives, and {3} True Positives'\n",
    "    ).format(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n",
    "\n",
    "\n",
    "classify_SVC(features_train, labels_train, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #TODO: Consider making graph of actual y/n poi on left, predicted y/n poi on right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on total payments and total stock value alone, we can determine the chance of someone being a person of interest with a reasonable accuracy.  While the prediction numbers look good at face value, this will not do as this model is predicting _everyone_ to not be a person of interest.  This result has far too many Type II errors to be a good indicator of who to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/165.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How often were persons of interest emailing each other?\n",
    "trace = go.Scatter(\n",
    "    x=df.from_poi_to_this_person,\n",
    "    y=df.from_this_person_to_poi,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size='12',\n",
    "        color=map(lambda x: 1 if x else 0, df.poi),\n",
    "        colorscale='Viridis',\n",
    "        showscale=True),\n",
    "    text=df.employee_name, )\n",
    "py.iplot([trace], filename='scatter-plot-with-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "#Assuming if we have no emails to a person in the records, there are none, as this data was obtained through legal discovery.\n",
    "df['from_poi_to_this_person'] = df['from_poi_to_this_person'].fillna(0)\n",
    "df['from_this_person_to_poi'] = df['from_this_person_to_poi'].fillna(0)\n",
    "df['from_poi_scaled'] = df['from_poi_to_this_person']\n",
    "df['to_poi_scaled'] = df['from_this_person_to_poi']\n",
    "\n",
    "df[['from_poi_scaled', 'to_poi_scaled']] = scaler.fit_transform(df[\n",
    "    ['from_poi_to_this_person', 'from_this_person_to_poi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~jennis/165.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How often were persons of interest emailing each other?\n",
    "trace = go.Scatter(\n",
    "    x=df.from_poi_scaled,\n",
    "    y=df.to_poi_scaled,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size='12',\n",
    "        color=map(lambda x: 1 if x else 0, df.poi),\n",
    "        colorscale='Viridis',\n",
    "        showscale=True),\n",
    "    text=df.employee_name, )\n",
    "py.iplot([trace], filename='scatter-plot-with-colorscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#That was interesting to see, but shouldn't be used for testing -- we don't want to scale based on all data points\n",
    "#then train PCA on some data points.\n",
    "df = df.drop(['from_poi_scaled'], axis=1)\n",
    "df = df.drop(['to_poi_scaled'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert the dataframe back into a dictionary\n",
    "my_dataset = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'from_poi_to_this_person', 'from_this_person_to_poi']\n",
    "create_test_split(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_test_scaled = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.004s\n"
     ]
    }
   ],
   "source": [
    "#create & fit PCA\n",
    "from sklearn.decomposition import PCA\n",
    "t0 = time()\n",
    "pca = PCA(n_components=2).fit(features_train_scaled)\n",
    "print \"done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train_transformed = pca.transform(features_train_scaled)\n",
    "features_test_transformed = pca.transform(features_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict without scaling or PCA\n",
      "training time: 0.001 s\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "prediction time: 0.001 s\n",
      "0.85\n",
      "accuracy time: 0.001 s\n",
      "0.0\n",
      "recall time: 0.001 s\n",
      "There are 17 True Negatives, 0 False Positives, 3 False Negatives, and 0 True Positives\n"
     ]
    }
   ],
   "source": [
    "print('Predict without scaling or PCA')\n",
    "classify_SVC(features_train, labels_train, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with scaling only\n",
      "training time: 0.003 s\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "prediction time: 0.001 s\n",
      "0.8\n",
      "accuracy time: 0.001 s\n",
      "0.0\n",
      "recall time: 0.002 s\n",
      "There are 16 True Negatives, 1 False Positives, 3 False Negatives, and 0 True Positives\n"
     ]
    }
   ],
   "source": [
    "print('Predict with scaling only')\n",
    "classify_SVC(features_train_scaled, labels_train, features_test_scaled,\n",
    "             labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with scaling and PCA\n",
      "training time: 0.002 s\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.]\n",
      "prediction time: 0.001 s\n",
      "0.8\n",
      "accuracy time: 0.001 s\n",
      "0.0\n",
      "recall time: 0.001 s\n",
      "There are 16 True Negatives, 1 False Positives, 3 False Negatives, and 0 True Positives\n"
     ]
    }
   ],
   "source": [
    "print('Predict with scaling and PCA')\n",
    "classify_SVC(features_train_transformed, labels_train,\n",
    "             features_test_transformed, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, based on the number of emails going between persons and known persons of interest, we cannot predict whether someone would be a person of interest with enough certainty.  I'd still like more false positives than false negatives, as we'd like to know who else to investigate when someone is suspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which brings us to my fleshed-out question -- were persons of interest better connected than non-POIs?  \n",
    "I'm specifically interested in how often persons of interest emailed the higher-paid staff at Enron vs non-POIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = [\n",
    "    'poi', 'total_payments', 'total_stock_value', 'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi'\n",
    "]\n",
    "create_test_split(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict using total payments, total stock, from poi, to poi\n",
      "training time: 0.001 s\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "prediction time: 0.001 s\n",
      "0.916666666667\n",
      "accuracy time: 0.001 s\n",
      "0.0\n",
      "recall time: 0.001 s\n",
      "There are 33 True Negatives, 0 False Positives, 3 False Negatives, and 0 True Positives\n"
     ]
    }
   ],
   "source": [
    "print('Predict using total payments, total stock, from poi, to poi')\n",
    "classify_SVC(features_train, labels_train, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's even worse.  Clearly we cannot use just these values to predict who is a POI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try selecting features based on the financial features and connectivity / how often the person sent poi emails\n",
    "features_list = ['poi'] + financial_features + [\n",
    "    'from_poi_to_this_person', 'from_this_person_to_poi'\n",
    "]\n",
    "create_test_split(features_list)\n",
    "\n",
    "kbest = SelectKBest(f_classif, k=10)\n",
    "selected_features = kbest.fit_transform(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectKBest:\n",
      "['salary', 'bonus', 'long_term_incentive', 'deferred_income', 'loan_advances', 'total_payments', 'exercised_stock_options', 'restricted_stock', 'total_stock_value', 'from_poi_to_this_person']\n"
     ]
    }
   ],
   "source": [
    "features_selected = [\n",
    "    features_list[i + 1] for i in kbest.get_support(indices=True)\n",
    "]\n",
    "\n",
    "print 'Features selected by SelectKBest:'\n",
    "print features_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest is suggesting we disregard email frequency to POIs in our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at the f score for each to validate that our selected scores had significantly higher scores than non-selected\n",
      "[0, 1, 2, 3, 5, 9, 10, 11, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 13.94966341,  16.76123647,   7.15671684,  15.74287286,\n",
       "         0.046985  ,   6.45380968,   3.6482477 ,   3.76265755,\n",
       "         1.54783121,   7.6658715 ,  23.26379643,   8.04137491,\n",
       "         0.71774165,  22.76795411,   4.45372207,   0.09446109])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'Looking at the f score for each to validate that our selected scores had significantly higher scores than non-selected'\n",
    "print [i for i in kbest.get_support(indices=True)]\n",
    "kbest.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'linearsvc__C': 4, 'pca__n_components': 3, 'pca__svd_solver': 'full'}\n"
     ]
    }
   ],
   "source": [
    "create_test_split(features_list)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# svc = svm.SVC()\n",
    "pipe = make_pipeline(MinMaxScaler(), PCA(), LinearSVC(), GradientBoostingClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'pca__n_components': range(1,16),\n",
    "    'pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "    'linearsvc__C': range(1,100)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "print(\"The best parameters are: {0}\").format(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tester Classification report\n",
      "Pipeline(steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=3, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False)), ('linearsvc', LinearSVC(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.80447\tPrecision: 0.24354\tRecall: 0.22150\tF1: 0.23200\tF2: 0.22558\n",
      "\tTotal predictions: 15000\tTrue positives:  443\tFalse positives: 1376\tFalse negatives: 1557\tTrue negatives: 11624\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'linearsvc__C': 1, 'pca__n_components': 1, 'pca__svd_solver': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "create_test_split(features_list)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "# svc = svm.SVC()\n",
    "pipe = make_pipeline(MinMaxScaler(), PCA(), LinearSVC(), GradientBoostingClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'pca__n_components': range(1,16),\n",
    "    'pca__svd_solver': ['auto', 'full', 'arpack', 'randomized'],\n",
    "    'linearsvc__C': range(1,100)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, cv=cv, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "print(\"The best parameters are: {0}\").format(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, iterated_power='auto', n_components=1, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('linearsvc', LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling...=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False))])\n",
      "\tAccuracy: 0.80400\tPrecision: 0.24401\tRecall: 0.22400\tF1: 0.23358\tF2: 0.22773\n",
      "\tTotal predictions: 15000\tTrue positives:  448\tFalse positives: 1388\tFalse negatives: 1552\tTrue negatives: 11612\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'selectkbest__k': 13, 'adaboostclassifier__n_estimators': 50, 'adaboostclassifier__learning_rate': 0.90000000000000002}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "create_test_split(features_list)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "pipe = make_pipeline(SelectKBest(), AdaBoostClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'selectkbest__k': range(1,15),\n",
    "    'adaboostclassifier__n_estimators': [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'adaboostclassifier__learning_rate': np.arange(0.1,1,0.1)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, cv=cv, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "print(\"The best parameters are: {0}\").format(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('selectkbest', SelectKBest(k=13, score_func=<function f_classif at 0x000000000CF9CE48>)), ('adaboostclassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.90000000000000002, n_estimators=50,\n",
      "          random_state=None))])\n",
      "\tAccuracy: 0.85967\tPrecision: 0.46377\tRecall: 0.33600\tF1: 0.38968\tF2: 0.35559\n",
      "\tTotal predictions: 15000\tTrue positives:  672\tFalse positives:  777\tFalse negatives: 1328\tTrue negatives: 12223\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'selectkbest__k': 13, 'adaboostclassifier__n_estimators': 50, 'adaboostclassifier__learning_rate': 0.90000000000000002}\n"
     ]
    }
   ],
   "source": [
    "#Add scaling\n",
    "create_test_split(features_list)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SelectKBest(), AdaBoostClassifier())\n",
    "\n",
    "parameters = {\n",
    "    'selectkbest__k': range(1,15),\n",
    "    'adaboostclassifier__n_estimators': [15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'adaboostclassifier__learning_rate': np.arange(0.1,1,0.1)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, parameters, cv=cv, scoring='recall')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "print(\"The best parameters are: {0}\").format(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('selectkbest', SelectKBest(k=13, score_func=<function f_classif at 0x000000000CF9CE48>)), ('adaboostclassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.90000000000000002, n_estimators=50,\n",
      "          random_state=None))])\n",
      "\tAccuracy: 0.85927\tPrecision: 0.46201\tRecall: 0.33750\tF1: 0.39006\tF2: 0.35673\n",
      "\tTotal predictions: 15000\tTrue positives:  675\tFalse positives:  786\tFalse negatives: 1325\tTrue negatives: 12214\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Future possibility, elephant is too large for scope right now: Consider checking for -- is there a group of words where the poi to poi emails [no non-pois in email?] had a higher usage\n",
    "#than those words in gen pop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
